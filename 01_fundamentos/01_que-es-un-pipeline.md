# ¬øQu√© es un pipeline de datos?

Un **pipeline de datos** es un sistema que **orquesta, ejecuta y monitorea** una serie de pasos para mover y transformar datos de forma **confiable y repetible**.

Un pipeline no es solo c√≥digo.
Es una **pieza de ingenier√≠a**.

---

## üß† Pipeline ‚â† Script

Un error com√∫n es pensar que un pipeline es simplemente:

* un script largo
* un cron job
* una secuencia de comandos

Eso puede funcionar al inicio, pero **no escala**.

### Diferencia clave

| Script              | Pipeline                  |
| ------------------- | ------------------------- |
| Ejecuta tareas      | Orquesta procesos         |
| Poco control        | Manejo de dependencias    |
| Dif√≠cil de observar | Monitoreable              |
| Fr√°gil              | Dise√±ado para fallar bien |

---

## üß± Elementos fundamentales de un pipeline

Un pipeline bien dise√±ado incluye:

### 1Ô∏è‚É£ Tareas

Unidades peque√±as y claras de trabajo:

* extraer datos
* transformar datos
* cargar resultados

Cada tarea hace **una sola cosa**.

---

### 2Ô∏è‚É£ Dependencias

Definen el orden correcto de ejecuci√≥n.

Ejemplo:

```text
Extraer ‚Üí Transformar ‚Üí Cargar
```

Sin dependencias claras:

* hay datos incompletos
* los resultados son inconsistentes

---

### 3Ô∏è‚É£ Manejo de errores

Los errores **van a ocurrir**.

Un pipeline debe:

* detectar fallos
* detenerse si es necesario
* permitir reintentos
* no corromper datos

---

### 4Ô∏è‚É£ Observabilidad

Saber qu√© est√° pasando.

Incluye:

* logs
* estados de ejecuci√≥n
* tiempos
* alertas

Un pipeline invisible es un pipeline peligroso.

---

## üîÑ Patrones de pipelines: ETL, ELT y m√°s

Los pipelines siguen diferentes **patrones arquitect√≥nicos** seg√∫n d√≥nde y cu√°ndo se realizan las transformaciones.

### üì• ETL: Extract, Transform, Load

**El patr√≥n tradicional.**

```text
Fuente ‚Üí Transformar ‚Üí Cargar al destino
```

**Flujo:**
1. **Extract**: Extraer datos de la fuente
2. **Transform**: Transformar en un sistema intermedio
3. **Load**: Cargar datos transformados al destino

**Caracter√≠sticas:**
* Las transformaciones ocurren **antes** de cargar
* Requiere un sistema intermedio para procesar
* Los datos llegan ya transformados al destino

**Ventajas:**
* Datos listos para consumo inmediato
* Menor carga en el destino
* Bueno para Data Warehouses tradicionales

**Desventajas:**
* Requiere infraestructura intermedia
* Menos flexible para cambios de esquema
* Puede ser m√°s lento

**Cu√°ndo usar:**
* Data Warehouses tradicionales (Redshift, Snowflake cl√°sico)
* Cuando el destino tiene capacidades limitadas de procesamiento
* Transformaciones complejas que requieren mucho c√≥mputo

---

### üì§ ELT: Extract, Load, Transform

**El patr√≥n moderno.**

```text
Fuente ‚Üí Cargar al destino ‚Üí Transformar en el destino
```

**Flujo:**
1. **Extract**: Extraer datos de la fuente
2. **Load**: Cargar datos crudos al destino
3. **Transform**: Transformar dentro del destino

**Caracter√≠sticas:**
* Los datos se cargan **primero** (crudos)
* Las transformaciones ocurren **en el destino**
* El destino debe ser capaz de procesar

**Ventajas:**
* M√°s flexible para cambios de esquema
* Menos infraestructura intermedia
* Datos crudos siempre disponibles
* Aprovecha el poder del destino (cloud warehouses)

**Desventajas:**
* Requiere un destino potente
* Puede ser m√°s costoso en procesamiento
* Datos crudos ocupan m√°s espacio

**Cu√°ndo usar:**
* **Data Lakes** (S3, ADLS, GCS) - El patr√≥n est√°ndar para Data Lakes
* Data Warehouses modernos (BigQuery, Snowflake, Databricks)
* Cuando necesitas flexibilidad en transformaciones
* Cuando quieres mantener datos crudos

---

### üîÑ ETLT: Extract, Transform, Load, Transform

**Patr√≥n h√≠brido.**

```text
Fuente ‚Üí Transformar (b√°sico) ‚Üí Cargar ‚Üí Transformar (avanzado)
```

**Flujo:**
1. **Extract**: Extraer datos
2. **Transform** (b√°sico): Limpieza y normalizaci√≥n inicial
3. **Load**: Cargar al destino
4. **Transform** (avanzado): Transformaciones complejas en el destino

**Caracter√≠sticas:**
* Combina lo mejor de ETL y ELT
* Transformaciones b√°sicas antes de cargar
* Transformaciones complejas despu√©s de cargar

**Cu√°ndo usar:**
* Cuando necesitas limpieza inicial pero tambi√©n flexibilidad
* Sistemas h√≠bridos con m√∫ltiples capas

---

### ‚¨ÖÔ∏è Reverse ETL

**Llevar datos del warehouse a sistemas operacionales.**

```text
Data Warehouse ‚Üí Transformar ‚Üí Sistemas operacionales (CRM, Marketing, etc.)
```

**Flujo:**
1. Extraer datos del Data Warehouse
2. Transformar para el sistema destino
3. Cargar a sistemas operacionales (Salesforce, HubSpot, etc.)

**Prop√≥sito:**
* Activar datos anal√≠ticos en sistemas operacionales
* Enriquecer sistemas CRM con insights
* Sincronizar datos entre sistemas

**Ejemplo:**
* Llevar segmentos de clientes del warehouse a herramientas de marketing
* Enviar m√©tricas calculadas a sistemas de ventas

---

### üìä Comparaci√≥n r√°pida

| Aspecto | ETL | ELT |
|---------|-----|-----|
| **Orden** | Transformar ‚Üí Cargar | Cargar ‚Üí Transformar |
| **Datos crudos** | No se guardan | Se guardan |
| **Infraestructura** | Requiere sistema intermedio | Menos infraestructura |
| **Flexibilidad** | Menor | Mayor |
| **Costo procesamiento** | En sistema intermedio | En destino |
| **Ideal para** | Warehouses tradicionales | **Data Lakes** y Warehouses modernos (cloud) |

> üí° **Data Lakes y ELT**: Los Data Lakes (S3, Azure Data Lake, Google Cloud Storage) **siempre usan ELT** porque est√°n dise√±ados para almacenar datos crudos y aplicar transformaciones al leerlos (schema-on-read). Esto permite m√°xima flexibilidad y evita perder datos originales.

---

### üéØ ¬øCu√°l elegir?

**Elige ETL si:**
* Tu destino tiene capacidades limitadas
* Necesitas datos listos para consumo inmediato
* Trabajas con Data Warehouses tradicionales

**Elige ELT si:**
* **Trabajas con Data Lakes** (S3, ADLS, GCS) - **ELT es el patr√≥n est√°ndar**
* Tienes un Data Warehouse moderno (cloud)
* Quieres mantener datos crudos
* Necesitas flexibilidad en transformaciones
* Quieres simplificar la arquitectura

**Elige Reverse ETL si:**
* Necesitas activar datos anal√≠ticos en sistemas operacionales
* Quieres enriquecer sistemas CRM/Marketing con insights

> üí° **En la pr√°ctica**: La mayor√≠a de sistemas modernos usan **ELT** porque los Data Warehouses cloud son muy potentes. ETL sigue siendo v√°lido para casos espec√≠ficos.

---

## üß≠ Pipelines como parte de un sistema mayor

Los pipelines no viven solos.

Normalmente forman parte de:

* Data Warehouses
* Data Lakes
* Plataformas anal√≠ticas

Por eso deben dise√±arse pensando en:

* escalabilidad
* mantenimiento
* impacto en otros equipos

---

## üß† Buen dise√±o de pipelines

Las buenas pr√°cticas en pipelines no son reglas r√≠gidas. Son **principios que reducen errores, facilitan el mantenimiento y permiten escalar**.

### 1. Dise√±a antes de escribir c√≥digo

Antes de programar, preg√∫ntate:

* ¬øCu√°l es la fuente del dato?
* ¬øQui√©n lo va a consumir?
* ¬øQu√© formato necesita?
* ¬øQu√© pasa si falla?
* ¬øSe puede reejecutar?
* ¬øQu√© datos produce?
* ¬øC√≥mo se valida la calidad?

Un pipeline pensado ahorra m√°s tiempo que uno r√°pido.

### 2. Una responsabilidad por proceso

Cada tarea debe hacer **una sola cosa**:

* extraer
* transformar
* cargar

Evita:

* funciones "todopoderosas"
* scripts interminables
* l√≥gica mezclada

> La claridad es una forma de escalabilidad.

### 3. Piensa en la reejecuci√≥n

Un pipeline bien dise√±ado:

* puede ejecutarse m√°s de una vez
* no duplica datos
* no corrompe resultados

Preg√∫ntate:

* ¬øpuedo reejecutar este proceso sin miedo?

La reejecuci√≥n segura es clave para operar.

### 4. Maneja errores expl√≠citamente

Los errores no deben:

* esconderse
* ignorarse
* corregirse manualmente

Buenas pr√°cticas:

* capturar excepciones
* fallar r√°pido
* registrar contexto
* alertar cuando es necesario

> Fallar bien es mejor que "parecer que funciona".

### 5. Agrega observabilidad desde el inicio

Incluso en pipelines simples:

* logs
* conteo de registros
* tiempos de ejecuci√≥n

Si no sabes qu√© pas√≥:

* no puedes arreglarlo
* no puedes escalarlo

### 6. Valida la calidad de los datos

No asumas que los datos son correctos.

Valida:

* esquemas
* valores nulos
* rangos
* duplicados

La calidad no es opcional. Es parte del pipeline.

### 7. Estructura tu c√≥digo

Evita:

* scripts sueltos
* l√≥gica duplicada

Prefiere:

* funciones reutilizables
* m√≥dulos
* carpetas claras

El orden reduce errores.

### 8. Nombra bien las cosas

Nombres claros para:

* funciones
* tablas
* columnas
* archivos

Malos nombres generan:

* confusi√≥n
* errores
* dependencia de personas espec√≠ficas

Si necesitas explicar un nombre, probablemente no es bueno.

### 9. Documenta decisiones, no solo c√≥digo

M√°s importante que *qu√© hace* el c√≥digo es:

* por qu√© existe
* qu√© problema resuelve
* qu√© trade-offs se tomaron

La documentaci√≥n ahorra tiempo futuro.

---

## üö´ Errores comunes que estas pr√°cticas evitan

* pipelines fr√°giles
* procesos manuales
* dependencia de una sola persona
* datos inconsistentes
* deuda t√©cnica innecesaria

Un pipeline bien pensado evita problemas futuros.

---

## ü§ñ ¬øD√≥nde entra la AI?

La AI puede ayudar a:

* documentar pipelines
* generar plantillas
* revisar l√≥gica b√°sica
* sugerir mejoras

Pero:

* no entiende tu contexto de negocio
* no asume la responsabilidad del resultado

---

## ‚û°Ô∏è ¬øQu√© sigue?

Para continuar:
* **[Batch vs Streaming](02_batch-vs-streaming.md)** - Tipos de procesamiento

Para profundizar:
* **[Pipelines b√°sicos](../05_pipelines/pipelines-basicos/)** - C√≥mo construir pipelines
* **[Orquestadores](../05_pipelines/orquestadores/)** - Herramientas para orquestar pipelines

---

**Un pipeline no se mide por lo complejo que es,
sino por lo confiable que resulta.**
