# Limpieza de datos

La limpieza de datos es una tarea fundamental en Data Engineering. Aprende tÃ©cnicas comunes para detectar y corregir problemas en tus datos.

> ðŸ’¡ **Usa el CSV de ejemplo**: `../data/ventas.csv` para practicar estos conceptos. Aunque este CSV estÃ¡ limpio, aprenderÃ¡s a detectar y limpiar problemas comunes.

---

## ðŸ” Detectar problemas

### Valores nulos

```python
# Cargar datos
df = pd.read_csv('../data/ventas.csv')

# Verificar nulos
print("Valores nulos por columna:")
print(df.isnull().sum())

# Porcentaje de nulos
print("\nPorcentaje de nulos:")
print((df.isnull().sum() / len(df) * 100).round(2))

# Filas con nulos
filas_con_nulos = df[df.isnull().any(axis=1)]
print(f"\nFilas con al menos un nulo: {len(filas_con_nulos)}")
```

### Duplicados

```python
# Detectar duplicados completos
duplicados = df.duplicated()
print(f"Duplicados completos: {duplicados.sum()}")

# Contar duplicados
print(f"Total de duplicados: {df.duplicated().sum()}")

# Ver duplicados
if df.duplicated().sum() > 0:
    print("\nDuplicados encontrados:")
    print(df[df.duplicated()])
else:
    print("\nâœ… No hay duplicados completos")

# Duplicados en columnas especÃ­ficas (ej: mismo producto vendido el mismo dÃ­a)
duplicados_producto_fecha = df.duplicated(subset=['producto', 'fecha'])
print(f"\nDuplicados en producto+fecha: {duplicados_producto_fecha.sum()}")
```

### Valores atÃ­picos (Outliers)

```python
# Usando IQR (Interquartile Range) para detectar outliers en precio
Q1 = df['precio'].quantile(0.25)
Q3 = df['precio'].quantile(0.75)
IQR = Q3 - Q1

limite_inferior = Q1 - 1.5 * IQR
limite_superior = Q3 + 1.5 * IQR

outliers = df[(df['precio'] < limite_inferior) | (df['precio'] > limite_superior)]
print(f"Outliers en precio: {len(outliers)}")
if len(outliers) > 0:
    print(outliers[['producto', 'precio', 'categoria']])
```

---

## ðŸ§¹ Limpiar datos

### Manejar nulos

```python
# Cargar datos
df = pd.read_csv('../data/ventas.csv')

# OpciÃ³n 1: Eliminar filas con nulos (si son pocos)
df_sin_nulos = df.dropna()
print(f"Registros originales: {len(df)}")
print(f"Registros despuÃ©s de dropna(): {len(df_sin_nulos)}")

# OpciÃ³n 2: Eliminar columnas con muchos nulos (>50%)
df_limpio = df.dropna(axis=1, thresh=len(df)*0.5)
print(f"Columnas originales: {len(df.columns)}")
print(f"Columnas despuÃ©s de filtrar: {len(df_limpio.columns)}")

# OpciÃ³n 3: Rellenar nulos
# Con promedio (para numÃ©ricos)
# df['precio'] = df['precio'].fillna(df['precio'].mean())

# Con valor fijo (para categÃ³ricos)
# df['ciudad'] = df['ciudad'].fillna('Desconocida')

# Con forward fill (rellena con valor anterior)
# df = df.fillna(method='ffill')  # Nota: method='ffill' estÃ¡ deprecado, usar ffill()
```

### Eliminar duplicados

```python
# Eliminar duplicados completos
df_limpio = df.drop_duplicates()
print(f"Registros originales: {len(df)}")
print(f"Registros despuÃ©s de eliminar duplicados: {len(df_limpio)}")

# Eliminar duplicados en columnas especÃ­ficas (mantener el primero)
df_limpio = df.drop_duplicates(subset=['producto', 'fecha'], keep='first')
print(f"Registros despuÃ©s de eliminar duplicados en producto+fecha: {len(df_limpio)}")
```

### Normalizar texto

```python
# Crear copia para no modificar original
df_limpio = df.copy()

# Eliminar espacios al inicio y final
df_limpio['producto'] = df_limpio['producto'].str.strip()
df_limpio['categoria'] = df_limpio['categoria'].str.strip()

# Convertir a mayÃºsculas/minÃºsculas (si fuera necesario)
# df_limpio['producto'] = df_limpio['producto'].str.upper()
# df_limpio['categoria'] = df_limpio['categoria'].str.lower()

# Reemplazar caracteres (ejemplo: si hubiera guiones)
# df_limpio['producto'] = df_limpio['producto'].str.replace('-', ' ')

print("âœ… Texto normalizado")
df_limpio[['producto', 'categoria']].head()
```

### Convertir tipos

```python
# Verificar tipos actuales
print("Tipos antes de conversiÃ³n:")
print(df.dtypes)

# Convertir fecha a datetime
df['fecha'] = pd.to_datetime(df['fecha'], format='%Y-%m-%d', errors='coerce')
print(f"\nFecha convertida. Tipo: {df['fecha'].dtype}")

# Convertir a numÃ©rico (si fuera necesario, aunque ya lo es)
# df['precio'] = pd.to_numeric(df['precio'], errors='coerce')

# Convertir a categorÃ­a (ahorra memoria para columnas con pocos valores Ãºnicos)
df['categoria'] = df['categoria'].astype('category')
df['ciudad'] = df['ciudad'].astype('category')

print("\nTipos despuÃ©s de conversiÃ³n:")
print(df.dtypes)
print(f"\nMemoria ahorrada: {df.memory_usage(deep=True).sum() / 1024:.2f} KB")
```

### Manejar valores atÃ­picos

```python
# OpciÃ³n 1: Eliminar outliers
Q1 = df['precio'].quantile(0.25)
Q3 = df['precio'].quantile(0.75)
IQR = Q3 - Q1

limite_inferior = Q1 - 1.5 * IQR
limite_superior = Q3 + 1.5 * IQR

df_sin_outliers = df[(df['precio'] >= limite_inferior) & (df['precio'] <= limite_superior)]
print(f"Registros originales: {len(df)}")
print(f"Registros sin outliers: {len(df_sin_outliers)}")
print(f"Outliers eliminados: {len(df) - len(df_sin_outliers)}")

# OpciÃ³n 2: Capar outliers (limitar valores extremos)
df_capped = df.copy()
df_capped['precio'] = df_capped['precio'].clip(lower=limite_inferior, upper=limite_superior)
print(f"\nPrecios capados entre {limite_inferior:.2f} y {limite_superior:.2f}")
```

---

## ðŸŽ¯ Ejercicios

> ðŸ’¡ **Usa el CSV de ejemplo**: `../data/ventas.csv` para practicar estos ejercicios.

### Ejercicio 1: Detectar problemas

```python
# 1. Carga el CSV de ventas
df = pd.read_csv('../data/ventas.csv')

# 2. Verifica valores nulos en todas las columnas
# Tu cÃ³digo aquÃ­

# 3. Verifica duplicados completos y en columnas especÃ­ficas (producto + fecha)
# Tu cÃ³digo aquÃ­

# 4. Detecta outliers en la columna 'precio' usando IQR
# Tu cÃ³digo aquÃ­
```

### Ejercicio 2: Limpiar datos bÃ¡sicos

```python
# 1. Crea una copia del DataFrame para trabajar
# Tu cÃ³digo aquÃ­

# 2. Convierte la columna 'fecha' a datetime
# Tu cÃ³digo aquÃ­

# 3. Convierte 'categoria' y 'ciudad' a tipo 'category' para ahorrar memoria
# Tu cÃ³digo aquÃ­

# 4. Normaliza el texto: elimina espacios en 'producto' y 'categoria'
# Tu cÃ³digo aquÃ­
```

### Ejercicio 3: Manejar duplicados y outliers

```python
# 1. Elimina duplicados completos (si los hay)
# Tu cÃ³digo aquÃ­

# 2. Elimina duplicados basados en 'producto' y 'fecha' (mantÃ©n el primero)
# Tu cÃ³digo aquÃ­

# 3. Detecta outliers en 'precio' y muestra cuÃ¡ntos hay
# Tu cÃ³digo aquÃ­

# 4. Crea un DataFrame sin outliers (elimina los valores extremos)
# Tu cÃ³digo aquÃ­
```

### Ejercicio 4: Limpieza completa

```python
# 1. Carga los datos
df = pd.read_csv('../data/ventas.csv')

# 2. Realiza una limpieza completa:
#    - Convierte 'fecha' a datetime
#    - Convierte 'categoria' y 'ciudad' a category
#    - Normaliza texto (strip en producto y categoria)
#    - Elimina duplicados en producto+fecha
#    - Detecta y muestra outliers en precio
# Tu cÃ³digo aquÃ­

# 3. Crea un resumen de la limpieza:
#    - Registros originales vs finales
#    - Duplicados eliminados
#    - Outliers detectados
#    - Tipos de datos corregidos
# Tu cÃ³digo aquÃ­
```

> ðŸ’¡ **Â¿Quieres ver ejemplos de cÃ³mo resolver estos ejercicios?** Revisa el notebook de ejemplo: **[04-limpieza-datos.ipynb](../../ejemplos/04-limpieza-datos.ipynb)** que muestra estas tÃ©cnicas aplicadas paso a paso.

---

## ðŸš€ Siguiente paso

ContinÃºa con **[Agregaciones y agrupaciones](04-agregaciones.md)**.
