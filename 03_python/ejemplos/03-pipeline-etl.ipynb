{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline ETL Simple\n",
    "\n",
    "Este notebook demuestra c√≥mo construir un pipeline ETL completo usando Python y Pandas.\n",
    "\n",
    "**Referencia:** [Fundamentos Python](../fundamentos/fundamentos-python.md)\n",
    "\n",
    "**Objetivos:**\n",
    "- Extraer datos de CSV\n",
    "- Transformar y limpiar datos\n",
    "- Cargar a base de datos (opcional)\n",
    "- Visualizar resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Cargar variables de entorno desde .env en la ra√≠z del proyecto\n",
    "env_path = Path().resolve().parent.parent / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"‚úÖ Variables de entorno cargadas desde .env\")\n",
    "else:\n",
    "    print(\"üí° No se encontr√≥ .env. Usando valores por defecto.\")\n",
    "    print(\"   Crea .env desde .env.example para configurar rutas y credenciales\")\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract: Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract: Cargar datos\n",
    "# En producci√≥n, cargar√≠as desde archivo usando rutas del .env\n",
    "\n",
    "# Obtener rutas desde variables de entorno o usar valores por defecto\n",
    "data_source = os.getenv('DATA_SOURCE_PATH', './data/raw')\n",
    "data_output = os.getenv('DATA_OUTPUT_PATH', './data/processed')\n",
    "\n",
    "print(f\"üìÅ Ruta de datos fuente: {data_source}\")\n",
    "print(f\"üìÅ Ruta de datos procesados: {data_output}\")\n",
    "\n",
    "# Para este ejemplo, creamos datos de ejemplo\n",
    "# En producci√≥n, usar√≠as: df = pd.read_csv(os.path.join(data_source, 'ventas.csv'))\n",
    "data = {\n",
    "    'fecha': ['2024-01-15', '2024-01-16', '2024-01-17', '2024-01-18', '2024-01-19'],\n",
    "    'producto': ['Producto A', 'Producto B', 'Producto A', 'Producto C', 'Producto B'],\n",
    "    'cantidad': [5, 3, 2, 1, 4],\n",
    "    'precio': [10.50, 25.00, 10.50, 50.00, 25.00],\n",
    "    'cliente': ['Cliente 1', 'Cliente 2', 'Cliente 1', 'Cliente 3', 'Cliente 2']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"\\n‚úÖ Extra√≠dos {len(df)} registros\")\n",
    "print(\"\\nPrimeras filas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transform: Limpiar y transformar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar para no modificar original\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Convertir fecha a datetime\n",
    "df_clean['fecha'] = pd.to_datetime(df_clean['fecha'])\n",
    "\n",
    "# Calcular total\n",
    "df_clean['total'] = df_clean['cantidad'] * df_clean['precio']\n",
    "\n",
    "# Eliminar duplicados\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "\n",
    "# Eliminar filas con valores nulos cr√≠ticos\n",
    "df_clean = df_clean.dropna(subset=['fecha', 'producto', 'cantidad', 'precio'])\n",
    "\n",
    "# Validar que cantidad y precio sean positivos\n",
    "df_clean = df_clean[\n",
    "    (df_clean['cantidad'] > 0) & \n",
    "    (df_clean['precio'] > 0)\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Transformados {len(df_clean)} registros\")\n",
    "print(\"\\nDatos transformados:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validar transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== VALIDACIONES ===\")\n",
    "print(f\"Registros originales: {len(df)}\")\n",
    "print(f\"Registros despu√©s de transformaci√≥n: {len(df_clean)}\")\n",
    "print(f\"Registros eliminados: {len(df) - len(df_clean)}\")\n",
    "print(f\"\\nTotal calculado: ‚Ç¨{df_clean['total'].sum():,.2f}\")\n",
    "print(f\"Promedio por transacci√≥n: ‚Ç¨{df_clean['total'].mean():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load: Visualizar resultados (simulado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load: Guardar datos procesados\n",
    "# Usar rutas desde variables de entorno\n",
    "\n",
    "# Crear directorio de salida si no existe\n",
    "os.makedirs(data_output, exist_ok=True)\n",
    "\n",
    "# Guardar como Parquet (formato recomendado para Data Engineering)\n",
    "output_file = os.path.join(data_output, 'ventas_procesadas.parquet')\n",
    "df_clean.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Datos guardados en: {output_file}\")\n",
    "print(f\"\\nüí° En producci√≥n, tambi√©n podr√≠as cargar a:\")\n",
    "print(\"  - PostgreSQL/MySQL (usando DB_HOST, DB_NAME del .env)\")\n",
    "print(\"  - Data Warehouse\")\n",
    "print(\"  - API (usando API_URL, API_KEY del .env)\")\n",
    "print(\"  - S3 (usando AWS_ACCESS_KEY_ID, S3_BUCKET_NAME del .env)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ventas por producto\n",
    "plt.figure(figsize=(10, 6))\n",
    "ventas_producto = df_clean.groupby('producto')['total'].sum().sort_values(ascending=True)\n",
    "ventas_producto.plot(kind='barh', color='steelblue')\n",
    "plt.title('Ventas Totales por Producto')\n",
    "plt.xlabel('Ventas Totales (‚Ç¨)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen del pipeline\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN DEL PIPELINE ETL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n‚úÖ Extract: {len(df)} registros extra√≠dos\")\n",
    "print(f\"‚úÖ Transform: {len(df_clean)} registros transformados\")\n",
    "print(f\"‚úÖ Total procesado: ‚Ç¨{df_clean['total'].sum():,.2f}\")\n",
    "print(f\"‚úÖ Promedio: ‚Ç¨{df_clean['total'].mean():,.2f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Pr√≥ximo paso:** Revisa otros notebooks:\n",
    "- [Exploraci√≥n de Datos](01-exploracion-datos.ipynb)\n",
    "- [Storytelling con Datos](02-storytelling-datos.ipynb)\n",
    "- [Limpieza de Datos](04-limpieza-datos.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
