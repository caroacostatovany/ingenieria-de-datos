{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline ETL Simple\n",
    "\n",
    "Este notebook demuestra cÃ³mo construir un pipeline ETL completo usando Python y Pandas.\n",
    "\n",
    "**Referencia:** [Fundamentos Python](../fundamentos/fundamentos-python.md)\n",
    "\n",
    "**Objetivos:**\n",
    "- Extraer datos de CSV\n",
    "- Transformar y limpiar datos\n",
    "- Cargar a base de datos (opcional)\n",
    "- Visualizar resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar librerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Cargar variables de entorno desde .env en la raÃ­z del proyecto\n",
    "env_path = Path().resolve().parent.parent / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"âœ… Variables de entorno cargadas desde .env\")\n",
    "else:\n",
    "    print(\"ðŸ’¡ No se encontrÃ³ .env. Usando valores por defecto.\")\n",
    "    print(\"   Crea .env desde .env.example para configurar rutas y credenciales\")\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract: Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract: Cargar datos\n",
    "# En producciÃ³n, cargarÃ­as desde archivo usando rutas del .env\n",
    "\n",
    "# Obtener rutas desde variables de entorno o usar valores por defecto\n",
    "data_source = os.getenv('DATA_SOURCE_PATH', '../data')\n",
    "data_output = os.getenv('DATA_OUTPUT_PATH', '../data/output')\n",
    "\n",
    "print(f\"ðŸ“ Ruta de datos fuente: {data_source}\")\n",
    "print(f\"ðŸ“ Ruta de datos procesados: {data_output}\")\n",
    "\n",
    "# Para este ejemplo, creamos datos de ejemplo\n",
    "# En producciÃ³n, usarÃ­as: df = pd.read_csv(os.path.join(data_source, 'ventas.csv'))\n",
    "data = {\n",
    "    'fecha': ['2024-01-15', '2024-01-16', '2024-01-17', '2024-01-18', '2024-01-19'],\n",
    "    'producto': ['Producto A', 'Producto B', 'Producto A', 'Producto C', 'Producto B'],\n",
    "    'cantidad': [5, 3, 2, 1, 4],\n",
    "    'precio': [10.50, 25.00, 10.50, 50.00, 25.00],\n",
    "    'cliente': ['Cliente 1', 'Cliente 2', 'Cliente 1', 'Cliente 3', 'Cliente 2']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"\\nâœ… ExtraÃ­dos {len(df)} registros\")\n",
    "print(\"\\nPrimeras filas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transform: Limpiar y transformar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar para no modificar original\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Convertir fecha a datetime\n",
    "df_clean['fecha'] = pd.to_datetime(df_clean['fecha'])\n",
    "\n",
    "# Calcular total\n",
    "df_clean['total'] = df_clean['cantidad'] * df_clean['precio']\n",
    "\n",
    "# Eliminar duplicados\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "\n",
    "# Eliminar filas con valores nulos crÃ­ticos\n",
    "df_clean = df_clean.dropna(subset=['fecha', 'producto', 'cantidad', 'precio'])\n",
    "\n",
    "# Validar que cantidad y precio sean positivos\n",
    "df_clean = df_clean[\n",
    "    (df_clean['cantidad'] > 0) & \n",
    "    (df_clean['precio'] > 0)\n",
    "]\n",
    "\n",
    "print(f\"âœ… Transformados {len(df_clean)} registros\")\n",
    "print(\"\\nDatos transformados:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validar transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== VALIDACIONES ===\")\n",
    "print(f\"Registros originales: {len(df)}\")\n",
    "print(f\"Registros despuÃ©s de transformaciÃ³n: {len(df_clean)}\")\n",
    "print(f\"Registros eliminados: {len(df) - len(df_clean)}\")\n",
    "print(f\"\\nTotal calculado: â‚¬{df_clean['total'].sum():,.2f}\")\n",
    "print(f\"Promedio por transacciÃ³n: â‚¬{df_clean['total'].mean():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load: Visualizar resultados (simulado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load: Guardar datos procesados\n",
    "# Usar rutas desde variables de entorno\n",
    "\n",
    "# Crear directorio de salida si no existe\n",
    "os.makedirs(data_output, exist_ok=True)\n",
    "\n",
    "# Guardar como Parquet (formato recomendado para Data Engineering)\n",
    "output_file = os.path.join(data_output, 'ventas_procesadas.parquet')\n",
    "df_clean.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"âœ… Datos guardados en: {output_file}\")\n",
    "print(f\"\\nðŸ’¡ En producciÃ³n, tambiÃ©n podrÃ­as cargar a:\")\n",
    "print(\"  - PostgreSQL/MySQL (usando DB_HOST, DB_NAME del .env)\")\n",
    "print(\"  - Data Warehouse\")\n",
    "print(\"  - API (usando API_URL, API_KEY del .env)\")\n",
    "print(\"  - S3 (usando AWS_ACCESS_KEY_ID, S3_BUCKET_NAME del .env)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ventas por producto\n",
    "plt.figure(figsize=(10, 6))\n",
    "ventas_producto = df_clean.groupby('producto')['total'].sum().sort_values(ascending=True)\n",
    "ventas_producto.plot(kind='barh', color='steelblue')\n",
    "plt.title('Ventas Totales por Producto')\n",
    "plt.xlabel('Ventas Totales (â‚¬)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen del pipeline\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN DEL PIPELINE ETL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nâœ… Extract: {len(df)} registros extraÃ­dos\")\n",
    "print(f\"âœ… Transform: {len(df_clean)} registros transformados\")\n",
    "print(f\"âœ… Total procesado: â‚¬{df_clean['total'].sum():,.2f}\")\n",
    "print(f\"âœ… Promedio: â‚¬{df_clean['total'].mean():,.2f}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ingenieria-de-datos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
